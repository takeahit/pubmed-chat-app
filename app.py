import requests
import xml.etree.ElementTree as ET
import streamlit as st
from openai import OpenAI

# --- Secrets ---
PUBMED_API_KEY = st.secrets["PUBMED_API_KEY"]
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
client = OpenAI(api_key=OPENAI_API_KEY)

BASE = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/"

# ====== 1) æ—¥æœ¬èªâ†’è‹±èªPubMedæ¤œç´¢å¼ å¤‰æ› ======
@st.cache_data(ttl=3600)
def jp_to_pubmed_query(jp_text: str) -> str:
    """
    æ—¥æœ¬èªã®è‡ªç„¶æ–‡ã‚’ã€è‹±èªã®PubMedæ¤œç´¢å¼(Boolean/MeSHå«ã‚€)ã«è¦ç´„å¤‰æ›ã™ã‚‹ã€‚
    ä¾‹ï¼‰ç³–å°¿ç—…ã®åˆä½µç—‡ã‚’SGLT2ã§â€¦ â†’ (diabetes mellitus[MeSH Terms] OR diabetes[tiab]) AND (SGLT2 inhibitors[MeSH Terms] OR SGLT2[tiab])
    """
    prompt = f"""
ã‚ãªãŸã¯PubMedã®æ¤œç´¢å¼ã‚’ä½œã‚‹å°‚é–€å®¶ã§ã™ã€‚
æ¬¡ã®æ—¥æœ¬èªè¦æœ›ã‹ã‚‰ã€è‹±èªã®PubMedæ¤œç´¢å¼ã‚’1è¡Œã§ä½œã£ã¦ãã ã•ã„ã€‚
- ã§ãã‚Œã° MeSH Terms ã¨ tiab ã‚’ä½µç”¨
- AND/OR/() ã‚’é©åˆ‡ã«
- ç¯„å›²æŒ‡ç¤ºï¼ˆå¹´ãªã©ï¼‰ãŒã‚ã‚Œã° english ã® pubdate ãƒ•ã‚£ãƒ«ã‚¿ã‚‚ä¾‹ç¤ºï¼ˆä¾‹ï¼š("2021"[Date - Publication] : "3000"[Date - Publication])ï¼‰
- å‡ºåŠ›ã¯å¼ã®ã¿ã€ä½™è¨ˆãªèª¬æ˜ã¯æ›¸ã‹ãªã„

æ—¥æœ¬èªè¦æœ›:
{jp_text}
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.1,
    )
    query = resp.choices[0].message.content.strip()
    # ä¸‡ä¸€ãƒãƒƒã‚¯ã‚¯ã‚©ãƒ¼ãƒˆãªã©ã§è¿”ã£ã¦ããŸã‚‰é™¤å»
    return query.replace("`", "").replace("\n", " ").strip()

# ====== 2) PubMedæ¤œç´¢ï¼ˆE-utilitiesï¼‰ ======
@st.cache_data(ttl=120)
def esearch(term: str, retmax: int = 10):
    params = {"db": "pubmed", "term": term, "retmax": retmax, "retmode": "json", "api_key": PUBMED_API_KEY}
    r = requests.get(BASE + "esearch.fcgi", params=params, timeout=30)
    r.raise_for_status()
    data = r.json()
    return data.get("esearchresult", {}).get("idlist", [])

@st.cache_data(ttl=120)
def efetch(pmids):
    if not pmids: return []
    params = {"db": "pubmed", "id": ",".join(pmids), "retmode": "xml", "api_key": PUBMED_API_KEY}
    r = requests.get(BASE + "efetch.fcgi", params=params, timeout=60)
    r.raise_for_status()
    root = ET.fromstring(r.text)
    out = []
    for art in root.findall(".//PubmedArticle"):
        pmid = art.findtext(".//PMID") or ""
        title = art.findtext(".//ArticleTitle") or ""
        abs_parts = []
        for ab in art.findall(".//AbstractText"):
            label = ab.get("Label")
            section = (label + ": " if label else "") + (ab.text or "")
            abs_parts.append(section)
        abstract = "\n".join(abs_parts) if abs_parts else "ï¼ˆè¦ç´„ãªã—ï¼‰"
        journal = art.findtext(".//Journal/Title") or ""
        year = art.findtext(".//Journal/JournalIssue/PubDate/Year") or ""
        out.append({"pmid": pmid, "title": title, "abstract": abstract, "journal": journal, "year": year})
    return out

# ====== 3) è‹±æ–‡è¦ç´„ã®ã‚„ã•ã—ã„æ—¥æœ¬èªè§£èª¬ ======
def summarize_with_gpt(text):
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {"role": "system", "content": "ã‚ãªãŸã¯åŒ»å­¦ã«è©³ã—ãã€ç°¡æ½”ã§æ­£ç¢ºãªæ—¥æœ¬èªè¦ç´„ãŒå¾—æ„ã§ã™ã€‚"},
            {"role": "user", "content": f"æ¬¡ã®PubMedæŠ„éŒ²ã‚’æ—¥æœ¬èªã§ã€è‡¨åºŠå®¶å‘ã‘ã«3ï½5è¡Œã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚\n\n{text}"}
        ],
        temperature=0.3
    )
    return resp.choices[0].message.content

# ====== UI ======
st.set_page_config(page_title="PubMed æ—¥æœ¬èªâ†’è‹±èªå¤‰æ›æ¤œç´¢ï¼‹ãƒãƒ£ãƒƒãƒˆ", page_icon="ğŸ”")
st.title("ğŸ” PubMed æ—¥æœ¬èªâ†’è‹±èªå¤‰æ›æ¤œç´¢ï¼‹ãƒãƒ£ãƒƒãƒˆ")

tab1, tab2 = st.tabs(["æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰", "ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰"])

# ---- æ¤œç´¢ãƒ¢ãƒ¼ãƒ‰ ----
with tab1:
    st.subheader("æ—¥æœ¬èªã®è‡ªç„¶æ–‡ã§æ¤œç´¢ã§ãã¾ã™")
    jp = st.text_area("æ—¥æœ¬èªã§æ›¸ã„ã¦ãã ã•ã„ï¼ˆä¾‹ï¼šã€2å‹ç³–å°¿ç—…ã§SGLT2é˜»å®³è–¬ã®è…ã‚¢ã‚¦ãƒˆã‚«ãƒ  2021å¹´ä»¥é™ã€ãªã©ï¼‰", "SGLT2é˜»å®³è–¬ã«ã‚ˆã‚‹2å‹ç³–å°¿ç—…æ‚£è€…ã®è…è‡“ã‚¢ã‚¦ãƒˆã‚«ãƒ  2021å¹´ä»¥é™")
    retmax = st.slider("å–å¾—ä»¶æ•°", 1, 20, 5)
    if st.button("æ¤œç´¢ã‚’å®Ÿè¡Œ"):
        with st.spinner("æ—¥æœ¬èª â†’ è‹±èªã®æ¤œç´¢å¼ã‚’ä½œæˆä¸­â€¦"):
            en_query = jp_to_pubmed_query(jp)
        st.caption("è‹±èªæ¤œç´¢å¼ï¼ˆç·¨é›†å¯ï¼‰")
        en_query = st.text_area("Generated PubMed query", en_query, height=80)
        with st.spinner("PubMedã‚’æ¤œç´¢ä¸­â€¦"):
            pmids = esearch(en_query, retmax)
        if not pmids:
            st.warning("è©²å½“ãªã—ã§ã—ãŸã€‚æ¤œç´¢å¼ã‚’å°‘ã—ç°¡å˜ã«ã—ã¦å†å®Ÿè¡Œã—ã¦ã¿ã¦ãã ã•ã„ã€‚")
        else:
            papers = efetch(pmids)
            for p in papers:
                with st.expander(f"{p['title'][:60]}..."):
                    st.markdown(f"**ã‚¿ã‚¤ãƒˆãƒ«**: {p['title']}")
                    st.markdown(f"**ã‚¸ãƒ£ãƒ¼ãƒŠãƒ«ãƒ»å¹´**: {p['journal']}ï¼ˆ{p['year']}ï¼‰")
                    st.markdown(f"[PubMedã§é–‹ã](https://pubmed.ncbi.nlm.nih.gov/{p['pmid']}/)")
                    st.markdown(f"**è¦ç´„ï¼ˆåŸæ–‡ï¼‰**:\n{p['abstract']}")
                    with st.spinner("AIãŒæ—¥æœ¬èªã§è¦ç´„ä¸­â€¦"):
                        st.success(summarize_with_gpt(p["abstract"]))

# ---- ãƒãƒ£ãƒƒãƒˆãƒ¢ãƒ¼ãƒ‰ ----
with tab2:
    st.subheader("è‡ªç„¶æ–‡ã§è³ªå• â†’ æ¤œç´¢å¼ã«è‡ªå‹•å¤‰æ› â†’ æ–‡çŒ®è¦ç´„ã‚’è¿”ç­”")
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for m in st.session_state.messages:
        with st.chat_message(m["role"]):
            st.write(m["content"])

    jp_input = st.chat_input("ä¾‹ï¼šã€å¿ƒä¸å…¨ã§SGLT2ã®å…¥é™¢æŠ‘åˆ¶åŠ¹æœ 2022å¹´ä»¥é™ã€ãªã©")
    if jp_input:
        st.session_state.messages.append({"role": "user", "content": jp_input})
        with st.chat_message("assistant"):
            with st.spinner("æ—¥æœ¬èªâ†’è‹±èªæ¤œç´¢å¼ã‚’ç”Ÿæˆä¸­â€¦"):
                en_query = jp_to_pubmed_query(jp_input)
            st.write("ç”Ÿæˆã—ãŸæ¤œç´¢å¼ï¼š")
            st.code(en_query)

            with st.spinner("PubMedæ¤œç´¢ä¸­â€¦"):
                pmids = esearch(en_query, 5)
                papers = efetch(pmids)

            if not papers:
                reply = "æ–‡çŒ®ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚æ¤œç´¢å¼ã‚’å°‘ã—ç·©ã‚ã¦ã¿ã¦ãã ã•ã„ã€‚"
                st.write(reply)
                st.session_state.messages.append({"role": "assistant", "content": reply})
            else:
                lines = []
                for p in papers:
                    jp_sum = summarize_with_gpt(f"{p['title']} ({p['journal']} {p['year']})\n{p['abstract']}")
                    lines.append(f"- **{p['title']}**ï¼ˆ{p['journal']} {p['year']}ï¼‰PMID:{p['pmid']}\n  {jp_sum}")
                reply = "\n\n".join(lines)
                st.write(reply)
                st.session_state.messages.append({"role": "assistant", "content": reply})
